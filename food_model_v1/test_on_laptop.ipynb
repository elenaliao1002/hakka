{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bf31894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import seaborn\n",
    "import glob\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9606063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './yolov5/'\n",
      "/Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/yolov5\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/exp2/weights/best.pt'], source=../food_roboflow_data/test2/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/requirements.txt not found, check failed.\n",
      "YOLOv5 ðŸš€ v7.0-145-g94714fe Python-3.8.13 torch-1.14.0.dev20221103 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s_food_robo summary: 157 layers, 7023610 parameters, 0 gradients\n",
      "image 1/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test2/images/img1.jpg: 416x352 1 spaghetti, 201.7ms\n",
      "image 2/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test2/images/img2.jpg: 320x416 1 spaghetti, 165.2ms\n",
      "image 3/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test2/images/img3.jpg: 320x416 (no detections), 109.8ms\n",
      "image 4/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test2/images/img4.jpg: 256x416 (no detections), 135.8ms\n",
      "image 5/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test2/images/img5.jpg: 288x416 1 salad, 148.4ms\n",
      "Speed: 0.8ms pre-process, 152.2ms inference, 2.1ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd ./yolov5/\n",
    "!python detect.py --weights ./runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source ../food_roboflow_data/test2/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "281571a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imageName in glob.glob('./yolov5/runs/detect/exp5/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cecb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './yolov5/'\n",
      "/Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/yolov5\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/exp2/weights/best.pt'], source=../food_roboflow_data/test3/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/requirements.txt not found, check failed.\n",
      "YOLOv5 ðŸš€ v7.0-145-g94714fe Python-3.8.13 torch-1.14.0.dev20221103 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s_food_robo summary: 157 layers, 7023610 parameters, 0 gradients\n",
      "image 1/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test3/images/img31.jpg: 416x288 1 banana, 2 salads, 181.8ms\n",
      "image 2/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test3/images/img32.jpg: 416x288 (no detections), 93.7ms\n",
      "image 3/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test3/images/img33.jpg: 256x416 2 pizzas, 1 spaghetti, 131.8ms\n",
      "image 4/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test3/images/img34.jpg: 320x416 1 salad, 145.6ms\n",
      "image 5/5 /Users/annieyuchuan/Desktop/USF/Spring2_project/food_model_v1/food_roboflow_data/test3/images/img35.jpg: 416x320 1 spaghetti, 147.7ms\n",
      "Speed: 0.2ms pre-process, 140.1ms inference, 0.6ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd ./yolov5/\n",
    "!python detect.py --weights ./runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source ../food_roboflow_data/test3/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c67693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imageName in glob.glob('./yolov5/runs/detect/exp6/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235a690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
